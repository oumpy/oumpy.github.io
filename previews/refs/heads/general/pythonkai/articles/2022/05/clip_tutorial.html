<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="" />
    <meta name="author" content="Python会" />
    <meta name="generator" content="Pelican (VoidyBootstrap theme)" />
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="CLIPを実装し理解する"/>
    <meta property="og:url" content="../../../blog/2022/05/clip_tutorial.html"/>
      <meta property="article:section" content="技術ブログ"/>
        <meta property="article:tag" content="Machine Learning"/>
      <meta property="article:author"
            content="Python会"/>
        <meta property="og:image"
              content="../../../images/images/logo.jpg"/>
    <meta name="twitter:card" content="summary"> 
    <meta name="twitter:title" content="CLIPを実装し理解する">
    <meta name="twitter:description" content="">
    <meta name="twitter:site" content="@oumed_python">
    <meta name="twitter:creator" content="@oumed_python">
    <meta name="twitter:domain" content="../../..">
        <meta property="twitter:image"
              content="../../../images/images/logo.jpg"/>

    <title>CLIPを実装し理解する - 大阪大学医学部 Python会 (テスト用ページ)</title>

   
        <link rel="stylesheet"
              href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
              integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk"
              crossorigin="anonymous">
      <link rel="stylesheet"
            href="https://use.fontawesome.com/releases/v5.13.0/css/all.css"
            integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V"
            crossorigin="anonymous">


      <link rel="stylesheet" href="../../../theme/css/pygment.css" />
      <link rel="stylesheet" href="../../../theme/css/theme.css" />
      <link rel="stylesheet" href="../../../theme/css/voidybootstrap-custom.css" />

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js" integrity="sha384-FFgGfda92tXC8nCNOxrCQ3R8x1TNkMFqDZVQdDaaJiiVbjkPBXIJBx0o7ETjy8Bh" crossorigin="anonymous"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js" integrity="sha384-ZoaMbDF+4LeFxg6WdScQ9nnR1QC2MIRxA1O9KWEXQwns1G8UNyIEZIQidzb0T1fo" crossorigin="anonymous"></script>
    <![endif]-->

    <link rel="shortcut icon" href="../../../favicon.ico" />
    <meta name="siteurl" property="og:siteurl" content="../../..">
    <meta name="source-repository" property="og:source-repository" content="https://github.com/oumpy/hp_management.git">
        <link href="/previews/refs/heads/general/pythonkai/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="大阪大学医学部 Python会 (テスト用ページ) Atom Feed" />
        <link href="/previews/refs/heads/general/pythonkai/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="大阪大学医学部 Python会 (テスト用ページ) RSS Feed" />
  </head>

  <body>
   
    <nav class="navbar navbar-expand py-0 fixed-top">
      <div class="container">
      <div class="row dropdown-hover-all">
        <a class="navbar-brand" href="../../../" rel="home">
          <i class="fa fa-home fa-fw fa-lg text-muted"> </i>
          </a>
		<button type="button" class="navbar-toggler" 
            data-toggle="collapse" data-target="#main-navbar-collapse"
            area-controls="main-navbar-collapse" area-extended="false">
      <span class="navbar-toggler-icon"></span>
		  <span class="sr-only">Toggle navigation</span>
		  <span class="icon-bar"></span>
		  <span class="icon-bar"></span>
		  <span class="icon-bar"></span>
		</button>
      <div class="collapse navbar-collapse" id="main-navbar-collapse">
        <div class="dropdown-hover-all">
          <ul class="nav navbar-nav mr-auto">
            <li class="nav-item dropdown dropdown-hover">
<a class="nav-link dropdown-toggle" id="dropdown1" href="../../../index.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Python会について</a>
<div class="dropdown-menu" aria-labelledby="dropdown1">
<a class="dropdown-item" href="../../../index.html">Python会について</a>
<div class="dropdown-divider"></div>
<a class="dropdown-item" href="../../../constitution.html">会規約</a>
</div>
</li>
<li class="nav-item dropdown dropdown-hover">
<a class="nav-link dropdown-toggle" id="dropdown4" href="../../../activities.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">活動内容</a>
<div class="dropdown-menu" aria-labelledby="dropdown4">
<a class="dropdown-item" href="../../../activities.html">活動内容</a>
<div class="dropdown-divider"></div>
<a class="dropdown-item" href="../../../activities.html#pelican-subsections-0">学習・研究</a>
<a class="dropdown-item" href="../../../activities.html#pelican-subsections-4">ワークショップ等の開催</a>
<a class="dropdown-item" href="../../../activities.html#pelican-subsections-5">過去の活動</a>
</div>
</li>
<li class="nav-item dropdown dropdown-hover">
<a class="nav-link dropdown-toggle" id="dropdown9" href="../../../achievements.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">実績</a>
<div class="dropdown-menu" aria-labelledby="dropdown9">
<a class="dropdown-item" href="../../../achievements.html">実績</a>
<div class="dropdown-divider"></div>
<a class="dropdown-item" href="../../../achievements.html#pelican-subsections-0">勉強会・成果発表活動</a>
<a class="dropdown-item" href="../../../achievements.html#pelican-subsections-4">会外部との連携によるイベント開催</a>
<a class="dropdown-item" href="../../../achievements.html#pelican-subsections-7">コンペティション実績</a>
<a class="dropdown-item" href="../../../achievements.html#pelican-subsections-14">研究開発活動</a>
<a class="dropdown-item" href="../../../achievements.html#pelican-subsections-23">所属メンバー論文</a>
<a class="dropdown-item" href="../../../achievements.html#pelican-subsections-29">出版記事等</a>
</div>
</li>
<li class="nav-item dropdown dropdown-hover active">
<a class="nav-link dropdown-toggle" id="dropdown17" href="../../../blog.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">技術ブログ</a>
<div class="dropdown-menu" aria-labelledby="dropdown17">
<a class="dropdown-item active" href="../../../blog.html">技術ブログ</a>
<div class="dropdown-divider"></div>
<a class="dropdown-item" href="../../../authors.html">著者一覧</a>
<a class="dropdown-item" href="../../../archives.html">過去記事一覧</a>
</div>
</li>
<li class="nav-item">
<a class="nav-link" href="../../../news.html">お知らせ</a>
</li>
<li class="nav-item dropdown dropdown-hover">
<a class="nav-link dropdown-toggle" id="dropdown22" href="../../../recruit.html" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">会員募集</a>
<div class="dropdown-menu" aria-labelledby="dropdown22">
<a class="dropdown-item" href="../../../recruit.html">会員募集</a>
<div class="dropdown-divider"></div>
<a class="dropdown-item" href="../../../recruit.html#pelican-subsections-0">Python会紹介動画 <!-- <small>[2020.07更新]</small> --></a>
<a class="dropdown-item" href="../../../recruit.html#pelican-subsections-1">新歓2021年度</a>
<a class="dropdown-item" href="../../../recruit.html#pelican-subsections-3">新歓2020年度</a>
</div>
</li>
<li class="nav-item">
<a class="nav-link" href="../../../contact.html">Contact</a>
</li>
        </ul> <!-- /nav -->
        </div> <!-- /dropdown-hover -->
      </div> <!-- /navbar-collapse -->
    </div> <!-- /row -->
    </div> <!-- /container -->
    </nav> <!-- /navbar -->

	<div class="jumbotron" id="overview">
	  <div class="container">
		<h1><a href="../../../">大阪大学医学部 Python会 (テスト用ページ)</a></h1>
		<p class="lead">Now is better than never.</p>
	  </div>
	</div>
    <meta name="article:slug" property="og:article:slug" content="clip_tutorial">
    <meta name="article:category" property="og:article:category" content="技術ブログ">
    <meta name="article:category:slug" property="og:article:category:slug" content="blog">
    <meta name="article:date" property="og:article:date" content="2022-05-24">

    <div class="container" id="main-container">
      <div class="row">
        <div class="col-md-9" id="content">
<article itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
  <header class="article-header">
<h1>
  <a href="../../../blog/2022/05/clip_tutorial.html" rel="bookmark"
     title="Permalink to CLIPを実装し理解する">
    CLIPを実装し理解する
  </a>
</h1><div class="article-header-info">
  <p>
<abbr class="article-header-date">
  2022-05-24(Tue)
</abbr>       - Posted by 
<a href="../../../author/chi-ce.html">池側</a>    in 
    <a href="../../../blog.html">
      技術ブログ</a>
    &nbsp;&nbsp;
        <a href="../../../tag/machine-learning.html"><img class="notebook-badge-image" src="https://img.shields.io/static/v1?label=Tag&message=Machine%20Learning&labelColor=black&color=darkorange" alt="tag:Machine Learning" title="tag:Machine Learning"></img></a>
  </p>
</div> <!-- /.article-header-info --><div id="colablink"></div><div class="toc_box">
    <span class="box-title">Contents</span>
      <ul id="toc"></ul>
</div>  </header>
  <div class="content-body" itemprop="text articleBody">
	<h2><span id="pelican-subsections-0">目的</span></h2>
<ul>
<li>CLIPを理解するため、<a href="https://github.com/openai">公式実装</a>や他の記事を参考にしながらCLIPを自分で実装してみました。</li>
<li>公式実装では他に様々な工夫がなされていますが、今回は最低限のコードでCLIPを分かり易く実装することを目的にしているため、性能については保証できません。</li>
<li>本記事はCLIPの実装と解説を主な目的としているため、論文の詳しい解説に関しては他の記事を参照してください。</li>
<li>自身で実装したモデルについて、学習は行っておりません。</li>
</ul>
<h2><span id="pelican-subsections-1">CLIPとは</span></h2>
<p>CLIP(Contrastive Language-Image Pre-Training)は、<a href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From Natural Language Supervision</a>においてOpenAIが発表した画像分類モデルの事前学習手法です。
CLIPでは、従来のようなラベル付き画像データセットを用いた教師あり学習ではなく、大量の画像とテキストのペアデータセットを用いて画像分類器を学習させています。この学習方法では、従来とは異なりデータセットに含まれるラベルの種類が限定されないため、幅広い種類の画像に対しての分類能力を得ることができます。その結果、初めて見るデータセットに関しても高い分類性能を示し、zero-shot性能が非常に高いモデルを作成することができます。</p>
<h2><span id="pelican-subsections-2">実装解説</span></h2>
<h3><span id="pelican-subsections-3">1. CLIPの全体的なアーキテクチャについて</span></h3>
<p>CLIPのアーキテクチャは以下の通りです。
CLIPは大きく画像をEmbeddingするImage Encoderと、文章をEmbeddingするText Encoderから構成されています。<br>
Embeddingとは、自然言語を計算が可能な形、すなわちベクトル表現に変換することを言います。CLIPのImage EncoderやText Encoderでは、1つの画像や文章をそれぞれ512次元のベクトルに変換しています。
Embeddingの詳しい説明に関しては<a href="https://qiita.com/sakabe/items/5f14999ded1de087c9b5">こちら</a>を参考にしてください。</p>
<p><img alt="" src="https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png"></p>
<h3><span id="pelican-subsections-4">2. Text Encoder</span></h3>
<p>CLIPのTextEncoderとしては、TransformerのEncoderが用いられています。<br>
Transformerは自然言語処理では必須のモデルで、全体として以下のようなアーキテクチャを持つモデルです。
TransformerのEncoderでは、次のように入力テキストの処理が行われます。</p>
<ol>
<li>トークン化された入力文章をEmbeddingする。</li>
<li>Positional Encodingを1でのEmbeddingに足し合わせることで文章中での位置情報を付与する。</li>
<li>MultiHeadAttention層とFeedForward層、これら層の後にそれぞれ続くResidual層+LayerNorm層の計4層からなるEncoderBlockに2での出力が渡され、順に処理が行われる。  </li>
<li>EncoderBlockでの処理がN回繰り返される。  </li>
</ol>
<p>各層の詳しい処理の説明はここでは割愛します。参考文献にある記事に詳しく説明がなされているのでそちらを参考にしてください。</p>
<p><img alt="" src="https://user-images.githubusercontent.com/57289763/160270884-e1901241-a1e6-4890-a5e8-165e87f0c4da.png"></p>
<p>TransformerのEncoderBlockの実装は次のようになります。<br>
ただし、CLIP内のTransformerのEncoderBlockでは、元のTransformerのものと異なり、LayerNormalizationをMultiHeadAttentionやFeedForwardNetwork層の後(=Post-Norm)ではなく前(=Pre-Norm)で行っています。  (参考：<a href="https://twitter.com/hillbig/status/1182438709095854080?s=19">Pre-Normを採用する理由</a>)</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">TransformerEncoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="c1"># Layer正規化した後にMultiHeadAttentionに入力し、その出力と元の値を足し合わせる</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_attention</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Layerした後にFeedForwardNetworkに入力し、その出力と元の値を足し合わせる</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="p">)</span> <span class="c1"># LayerNorm-&gt;FeedForwardNetwork-&gt;Add</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<p>TransformerのEncoderは、上で定義した<code>TransformerEncoderBlock</code>を用いて以下のように実装できます。ただし、オリジナルのTransformerでは、Positional Encodingはsin関数やcos関数を用いていますが、実装では0~1の一様分布からランダムに選択した値を持つ学習可能なパラメータとなっています。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">context_length</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder_blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">TransformerEncoderBlock</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layers</span><span class="p">)]</span>
            <span class="p">)</span> 

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 1. トークン化された文章をベクトル表現に変換</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span>  <span class="c1"># 2. Positional Encodingにより位置情報を付与</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder_blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 3+4. TransformerEncoderBlockでの処理をN回くり返す</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<h3><span id="pelican-subsections-5">3. Image Encoderの実装</span></h3>
<p>CLIPのImage EncoderとしてはResNetやVisionTransformerが用いられています。今回はVisionTransformerを用いて実装を行っていきます。
VisionTransformerは上で実装したTransformer Encoderを、自然言語処理ではなく画像分類に適用するためのモデルです。
VisionTransformerでは以下のような順番で画像の処理が行われます。</p>
<ol>
<li>元の画像を分割したもの(=パッチ)を作成し、これをEmbeddingしたものを横に並べる。</li>
<li>1で作成したパッチの列の先頭に分類用のclass tokenをEmbeddingしたものを追加する。</li>
<li>2で作成したパッチとclass tokenのEmbeddingにPositional Embeddingを足し合わせ、パッチ列中での位置情報を付与する。<ul>
<li>ViTのPositional Encodingでは、学習可能なパラメータを用いている。</li>
</ul>
</li>
<li>3の出力をTransformer Encoderに掛ける</li>
<li>class tokenに相当する部分のEmbeddingをMLPに入力する。</li>
<li>5の出力を元にクラス分類を行う。</li>
</ol>
<p><img alt="" src="https://storage.googleapis.com/zenn-user-upload/aa5ae6bcb822784d6021ea6a.png"></p>
<p>Image Encoderでは、画像1枚1枚に対して通常のVisionTransformerと同様に1~4の処理を行います。具体的な実装は以下の通りです。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">VisionTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">=</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span>
        <span class="n">patch_height</span><span class="p">,</span> <span class="n">patch_width</span> <span class="o">=</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">patch_size</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_height</span> <span class="o">//</span> <span class="n">patch_height</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">image_width</span> <span class="o">//</span> <span class="n">patch_width</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">class_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span> <span class="c1"># class_tokenのEmbeddingに相当</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span> <span class="c1"># num_pathes + 1 = patch数+class_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_pre</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">TransformerEncoderBlock</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layers</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_post</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__image_to_patch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            入力画像をパッチに変換する。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__image_to_patch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 1. 画像をパッチに変換しEmbeddingする</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">class_embedding</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 2. class tokenのembeddingをパッチの先頭に追加</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 3. positional encodingで位置情報を追加</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_pre</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 4. パッチのembeddingをTransformerEncoderに入力</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<h3><span id="pelican-subsections-6">4. CLIPの実装</span></h3>
<p>次に、上の1,2で実装した<code>TransformerEncoder</code>や<code>VisionTransformer</code>を用いて、CLIPを実装していきます。<br>
CLIPの実装は以下のようになります。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">CLIP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">224</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span>
        <span class="n">layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
        <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">77</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">49408</span><span class="p">,</span>
        <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># image encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_encoder</span> <span class="o">=</span> <span class="n">VisionTransformer</span><span class="p">(</span>
            <span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span><span class="p">,</span>
            <span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span><span class="p">,</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">width</span><span class="p">,</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span><span class="p">,</span>
            <span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span><span class="p">,</span>
            <span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>

        <span class="c1"># text encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="o">=</span> <span class="n">context_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">context_length</span> <span class="o">=</span> <span class="n">context_length</span><span class="p">,</span>
            <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">width</span><span class="p">,</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span><span class="p">,</span>
            <span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">temperature_parameter</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mf">0.07</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">encode_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Image Encoderを用いて画像をImage Embeddingに変換</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_encoder</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_projection</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">encode_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Text Encoderを用いてテキストをText Embeddingに変換</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tokenize</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="c1"># print(x)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span> <span class="c1"># EOT tokenのembeddingのみ使用する</span>
        <span class="c1"># print(x[0])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">__tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">truncate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            byte-pair Encodingの手法を用いて、テキストをtokenに変換する。</span>
<span class="sd">            byte-pair Encodingの詳細は本記事では省略する。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">_Tokenizer</span><span class="p">()</span>
        <span class="n">sot_token</span> <span class="o">=</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">]</span>
        <span class="n">eot_token</span> <span class="o">=</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">]</span>
        <span class="n">all_tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">sot_token</span><span class="p">]</span> <span class="o">+</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">eot_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">)]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">),</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">context_length</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">truncate</span><span class="p">:</span>
                    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">context_length</span><span class="p">]</span>
                    <span class="n">tokens</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">eot_token</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input </span><span class="si">{</span><span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> is too long for context length </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">__l2_normalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; L2正規化を行うメソッド &quot;&quot;&quot;</span>
        <span class="n">x_l2_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span>
        <span class="n">x_l2_norm</span> <span class="o">=</span> <span class="n">x_l2_norm</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">x_l2_norm</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">texts</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            logitsを計算する。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># L2 Normalization</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__l2_normalization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">images</span><span class="p">))</span>
        <span class="n">text_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__l2_normalization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>

        <span class="c1"># logitsを計算</span>
        <span class="n">logits_per_image</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_embeddings</span> <span class="o">@</span> <span class="n">text_embeddings</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature_parameter</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
        <span class="n">logits_per_text</span> <span class="o">=</span> <span class="p">(</span><span class="n">text_embeddings</span> <span class="o">@</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature_parameter</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">logits_per_image</span><span class="p">,</span> <span class="n">logits_per_text</span>
</code></pre></div>

<p><code>encode_image</code>では、<code>VisionTransformer</code>の<code>TransformerEncoder</code>の最終出力のうち、class_token、すなわち<code>index==0</code>の位置にあるEmbeddingを取り出します。その後、<code>image_projection</code>により512次元のベクトルに変換し、最終的なCLIPの画像特徴量とします。<br>
また、<code>encode_text</code>では、<code>TransformerEncoder</code>の最終出力のうち、EOT(End Of Text)、すなわち最も大きいtokenの値を持つindexにあるEmbeddingを取り出します。その後、<code>text_projection</code>により512次元のベクトルに変換し、最終的なCLIPの文章特徴量とします。<br>
<code>forward</code>では、与えられた画像とテキストの入力をエンコードし、logitsを計算します。具体的には以下のような順番で処理を行っています。
1. encode_imageやencode_textを用いて画像やテキストをCLIPのEmbeddingに変換
2. 1で変換したEmbeddingをL2正規化
    - L2正規化については<a href="https://qiita.com/panda531/items/4ca6f7e078b749cf75e8">こちらの記事</a>を参照
3. 画像とテキストのCLIP特徴量の行列積を計算することで、画像/テキスト毎のlogitsを取得</p>
<h3><span id="pelican-subsections-7">4. Symmetric Lossの実装</span></h3>
<p>CLIPでは対照学習を行っています。具体的には、1バッチ内の画像とテキストについて、元々のペアを正例、それ以外のペアを負例とすると、学習時には正例との類似度が高く、負例との類似度が低くなるように学習を行います。
論文中では以下のような疑似コードが掲載されていました。この疑似コードに関しては<a href="https://data-analytics.fun/2021/03/24/understanding-openai-clip/">こちらの記事</a>で詳しく解説されています。</p>
<p><img alt="" src="https://data-analytics.fun/wp-content/uploads/2021/01/image-58.png"></p>
<p>また、この疑似コードを元にSymmetric Lossの実装を行ってみました。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">SymmetricLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits_per_image</span><span class="p">,</span> <span class="n">logits_per_text</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">loss_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">logits_per_image</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># 画像に対するloss</span>
        <span class="n">loss_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">logits_per_text</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="c1"># テキストに対するloss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_i</span> <span class="o">+</span> <span class="n">loss_t</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>

<h2><span id="pelican-subsections-8">感想</span></h2>
<p>初めての記事執筆でした。読みにくい箇所もあるかと思いますがご容赦下さい。<br>
普段からCLIPに関してはOpenAIが提供している事前学習済みモデルを使用しているのですが、自分で実装しながら記事を書いてみると、TransformerやViT、CLIPへの理解がより深まりました。</p>
<h2><span id="pelican-subsections-9">参考文献</span></h2>
<ol>
<li><a href="https://deepsquare.jp/2021/01/clip-openai/">話題のOpenAIの新たな画像分類モデルCLIPを論文から徹底解説！</a>  </li>
<li><a href="https://data-analytics.fun/2021/03/24/understanding-openai-clip/#toc3">【論文解説】自然言語処理と画像処理の融合 – OpenAI 『CLIP』を理解する(1)</a>  </li>
<li><a href="https://zenn.dev/yukiyada/articles/59f3b820c52571#3.6-encoder">Python(PyTorch)で自作して理解するTransformer</a>  </li>
<li><a href="https://zenn.dev/ronly/articles/5a0d3527c2945d#vision-transformer">【Vision Transformer】 コード解説</a></li>
<li><a href="https://qiita.com/panda531/items/4ca6f7e078b749cf75e8">PythonでベクトルをL2正規化(normalization)する方法一覧</a></li>
</ol>
  </div>
  
<div class="article-tag-list">
<span class="label label-default">Tags</span>
	<a href="../../../tag/machine-learning.html"><i class="fa fa-tag"></i>Machine Learning</a>&nbsp;
</div><hr><ul>
        <li>
            前の記事 :
            <a href="../../../blog/2022/05/zapline.html">
                ZapLineを用いたLFPに対する電源由来のアーティファクト除去 (Python)
            </a>
        </li>
        <li>
            次の記事 :
            <a href="../../../blog/2022/06/medicalrecord_competition.html">
                英語のカルテデータのコンペに参加してみた(際の失敗と反省)
            </a>
        </li>
        <li>    
            関連記事 :
            <ul>
                <li><a href="../../../blog/2023/01/medicalssl.html">医療画像と自己教師あり学習まとめ</a></li>
                <li><a href="../../../blog/2022/07/wsi_ssl.html">WSI＊自己教師あり学習のメモ</a></li>
                <li><a href="../../../blog/2022/04/crohn.html">クローン病の予後予測と脂肪組織萎縮の関係</a></li>
            </ul>
        </li>
</ul>  <hr />
  <div class="well well-sm">  <!-- Social media sharing buttons -->
    <!-- Twitter -->
    <a href="https://twitter.com/share" class="twitter-share-button" 
       data-via="oumed_python" >Tweet</a>&nbsp;

    <!-- Google+ -->
    <div class="g-plus" data-action="share" data-annotation="bubble"></div>
    &nbsp;&nbsp;&nbsp;&nbsp;
    <div class="g-plusone" data-size="medium"></div>&nbsp;

    <!-- Facebook -->
    <div class="fb-like" 
        data-href="../../../blog/2022/05/clip_tutorial.html" 
        data-layout="button_count" 
        data-action="like" data-show-faces="true" 
        data-share="true">
    </div>
    &nbsp;
  </div> <!-- /Social media sharing buttons --><!-- Comment system with utteranc.es -->
<script src="https://utteranc.es/client.js"
        repo="oumpy/oumpy.github.io"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
</article>
        </div><!-- /content -->

        <div class="col-md-3 sidebar-nav" id="sidebar">
<div class="row"><div class="col-md-12 col-sm-4 col-xs-12">
<form id="cse-search-box" action="../../../search.html">
<input type="hidden" name="ie" value="UTF-8">
<input type="text" name="q" placeholder="サイト内を検索" style="height: 1.7em; width: 82.5%;">
<input type="submit" value="&#xf002;" class="fas" style="height: 1.7em; width: 15%;">
</form>
<div class="sidebar_box">
<div class="box-title"><i class="fa fa-comment fa-fw fa-lg"></i> ソーシャル</div>
<div class="box-contents">
<ul class="list-unstyled social-links">
  <li><a href="https://twitter.com/oumed_python" target="_blank" title="Twitter">
    <span style="color:#1DA1F2; font-size:larger;"><i class="fab fa-twitter"></i><span>
  </a></li>
  <li><a href="mailto:handai.python@gmail.com" target="_blank" title="E-mail">
    <span style="color:#0078D4; font-size:larger;"><i class="far fa-envelope"></i><span>
  </a></li>
  <li><a href="https://github.com/oumpy" target="_blank" title="GitHub Organization">
    <span style="color:#211F1F; font-size:larger;"><i class="fab fa-github"></i><span>
  </a></li>
  <li><a href="https://www.youtube.com/channel/UCh1eAeDCpsZeOh0Z9paNfHQ" target="_blank" title="YouTube Channel">
    <span style="color:#c4302b; font-size:larger;"><i class="fab fa-youtube"></i><span>
  </a></li>
  <li><a href="https://oum-python.connpass.com" target="_blank" title="Connpass">
    <span style="color:#000000; font-size:normal;"><img width="35px" src="https://connpass.com/static/img/72_72.png" style="display: inline;"/><span>
  </a></li>
  <li><a href="../../../feeds/all.atom.xml" target="_blank" title="Atom Feed">
    <span style="color:#00008b; font-size:smaller;"><i class="fa fa-rss fa-fw fa-lg"></i><span>
  </a></li>
  <li><a href="../../../feeds/all.rss.xml" target="_blank" title="RSS Feed">
    <span style="color:#f26522; font-size:normal;"><i class="fas fa-rss-square fa-fw fa-lg"></i><span>
  </a></li>
</ul>
</div>
</div>
<div class="sidebar_box">
<div class="box-title"><i class="fas fa-bell"></i> 新着記事</div>
<div class="box-contents">
<div class="horizontal-scroll">
<table class="recent-posts" id="recentposts">
  <tr><td colspan="3"><span class="recent-posts-year">2023</span></td></tr>
  <tr>
    <td class="recent-posts-date">10/1</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../news.html">News</a>]</span></td>
    <td><a href="../../../news/2023/10/party_renewal.html"><span class="recent-posts-title">Python会は情報医科学研究会より分会しました</span></a></td>
  </tr>
  <tr>
    <td class="recent-posts-date">1/3</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2023/01/medicalssl.html"><span class="recent-posts-title">医療画像と自己教師あり学習まとめ</span></a></td>
  </tr>
  <tr><td colspan="3"><span class="recent-posts-year">2022</span></td></tr>
  <tr>
    <td class="recent-posts-date">9/17</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2022/09/statistics_certificate.html"><span class="recent-posts-title">統計検定準1級 合格体験記</span></a></td>
  </tr>
  <tr>
    <td class="recent-posts-date">9/4</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2022/09/nonabelian_1loop.html"><span class="recent-posts-title">非可換ゲージ理論の頂点計算機</span></a></td>
  </tr>
  <tr>
    <td class="recent-posts-date">8/9</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2022/08/reflecting-kde.html"><span class="recent-posts-title">境界条件を伴うカーネル密度推定</span></a></td>
  </tr>
  <tr>
    <td class="recent-posts-date">7/3</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2022/07/wsi_ssl.html"><span class="recent-posts-title">WSI＊自己教師あり学習のメモ</span></a></td>
  </tr>
  <tr>
    <td class="recent-posts-date">6/10</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2022/06/medicalrecord_competition.html"><span class="recent-posts-title">英語のカルテデータのコンペに参加してみた(際の失敗と反省)</span></a></td>
  </tr>
  <tr>
    <td class="recent-posts-date">5/24</td>
    <td><span class="recent-posts-prefix-category">[<a href="../../../blog.html">Blog</a>]</span></td>
    <td><a href="../../../blog/2022/05/clip_tutorial.html"><span class="recent-posts-title">CLIPを実装し理解する</span></a></td>
  </tr>
</table>
</div>
</div>
</div>
<div class="sidebar_box">
<div class="box-title"><i class="fa fa-tags fa-fw fa-lg"></i> タグ一覧</div>
<p class="tag-cloud">
    <span class="tag-3">
      <a href="../../../tag/neuroscience.html">
          <span class="badge badge-primary">4</span>
        Neuroscience
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/zi-dong-hua.html">
          <span class="badge badge-primary">6</span>
        自動化
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/mian-qiang-hui.html">
          <span class="badge badge-primary">10</span>
        勉強会
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/jian-ding-shi-yan.html">
          <span class="badge badge-primary">4</span>
        検定試験
      </a>
    </span>
    <span class="tag-4">
      <a href="../../../tag/hai-wai-liu-xue.html">
          <span class="badge badge-primary">1</span>
        海外留学
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/sonota-yan-yu.html">
          <span class="badge badge-primary">2</span>
        その他言語
      </a>
    </span>
    <span class="tag-4">
      <a href="../../../tag/github.html">
          <span class="badge badge-primary">1</span>
        GitHub
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/jing-ji-puroguramingu.html">
          <span class="badge badge-primary">8</span>
        競技プログラミング
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/lun-wen-matome.html">
          <span class="badge badge-primary">7</span>
        論文まとめ
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/bioinformatics.html">
          <span class="badge badge-primary">14</span>
        Bioinformatics
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/news.html">
          <span class="badge badge-primary">9</span>
        News
      </a>
    </span>
    <span class="tag-4">
      <a href="../../../tag/lun-wen-guan-lian.html">
          <span class="badge badge-primary">1</span>
        論文関連
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/qi-ye-intan.html">
          <span class="badge badge-primary">2</span>
        企業インターン
      </a>
    </span>
    <span class="tag-1">
      <a href="../../../tag/machine-learning.html">
          <span class="badge badge-primary">28</span>
        Machine Learning
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/simulation.html">
          <span class="badge badge-primary">2</span>
        Simulation
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/hadouea.html">
          <span class="badge badge-primary">2</span>
        ハードウェア
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/unix.html">
          <span class="badge badge-primary">2</span>
        Unix
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/shell-script.html">
          <span class="badge badge-primary">3</span>
        Shell script
      </a>
    </span>
    <span class="tag-3">
      <a href="../../../tag/mian-xue-zhi-yuan.html">
          <span class="badge badge-primary">2</span>
        勉学支援
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/statistics.html">
          <span class="badge badge-primary">12</span>
        Statistics
      </a>
    </span>
    <span class="tag-2">
      <a href="../../../tag/data-science-competition.html">
          <span class="badge badge-primary">7</span>
        Data Science Competition
      </a>
    </span>
    <span class="tag-1">
      <a href="../../../tag/python.html">
          <span class="badge badge-primary">20</span>
        Python
      </a>
    </span>
</p>
</div><div class="sidebar_box">
<div class="box-title"><i class="fas fa-hand-holding-heart"></i> 会へのご支援</div>
<div class="box-contents">
<div style="display:flex; justify-content:center;">
<ul style="list-style:none; padding-left:0;">
  <li>
    <a href="https://paypal.me/oumpy/"><span style="font-size:larger;"><span class="text-primary" style="margin-right:5px;"><i class="fab fa-paypal"></i></span><font color="#003087">Pay</font><font color="#009cde">Pal</font><font color="#012169">.Me</font></span></a><br><span style="font-size:smaller; margin-left:0px;">(<a href="/previews/refs/heads/general/pythonkai/donations.html">ご寄付を頂いた方々</a>)</span>
  </li>
</ul>
</div>
</div>
</div></div> <!-- col -->
<div class="col-md-12 col-sm-8 col-xs-12">
<div class="sidebar_box">
<div class="box-title"><i class="fab fa-twitter fa-fw fa-lg"></i> Timeline</div>
<div class="box-contents">
    <a class="twitter-timeline" data-height=600 href=https://twitter.com/oumed_python?ref_src=twsrc%5Etfw>Tweets by oumed_python</a>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</div>
</div></div>  <!-- row, col -->        </div><!--/sidebar -->
      </div><!--/row-->
    </div><!--/.container /#main-container -->

    <footer id="site-footer">
<!-- colophon  -->
<!-- Site built using Pelican.  Theme based on VoidyBootstrap. -->
<address id="site-colophon" style="padding-top:0rem;padding-bottom:0.03rem;">
    <div class="text-center">
    <p class="text-dark" style="margin:0px">
        © 2023 大阪大学医学部Python会
    </p>
    <p class="text-muted">
    Site built using <a href="http://getpelican.com/" target="_blank">Pelican</a>
    powered by <a href="https://www.python.org/">Python</a>
    &nbsp;&bull;&nbsp; Theme based on
    <a href="http://www.voidynullness.net/page/voidy-bootstrap-pelican-theme/"
       target="_blank">VoidyBootstrap</a> by 
    <a href="http://www.robertiwancz.com/"
       target="_blank">RKI</a>  
    </p>
    </div>
</address><!-- /colophon  --> 
      <!-- Site built using Pelican.  Theme based on VoidyBootstrap. -->
    </footer>


    <!-- javascript -->
   
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
            integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
            crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
            integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
            crossorigin="anonymous"></script>
    <!-- https://github.com/dallaslu/bootstrap-4-multi-level-dropdown -->
    <script src="https://raw.githubusercontent.com/dallaslu/bootstrap-4-multi-level-dropdown/master/bootstrap4-dropdown-ml-hack-hover.js"></script>


<!-- Facebook -->
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));
</script>

<!-- Twitter -->
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<!-- Google+ -->
<!-- Synchronous 
<script type="text/javascript" src="https://apis.google.com/js/plusone.js"></script>
-->
<!-- Asynchronous -->
<script type="text/javascript">
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/platform.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script><script>
const colab_img_url = 'https://colab.research.google.com/assets/colab-badge.svg'
const github_img_url = 'https://img.shields.io/static/v1?label=&logo=github&message=View%20On%20GitHub&labelColor=black&color=gray'
const colab_img = '<img class="notebook-badge-image" src="' + colab_img_url + '" alt="Open In Colab" title="Open In Colab" width="119px"></img>';
const github_img = '<img class="notebook-badge-image" src="' + github_img_url + '" alt="View On GitHub" title="View On GitHub" width="124px"></img>';
var check_ipynb = document.getElementsByClassName('highlight hl-ipython3');
if (check_ipynb.length > 0) {
    var doc0 = document.getElementById("colablink");
    var article_date = document.getElementsByName('article:date')[0].content;
    var article_year = article_date.slice(0, 4);
    var article_month = article_date.slice(5, 7);
    var article_category = document.getElementsByName('article:category:slug')[0].content; 
    if (parseInt(article_month) <= 3) {
      article_year = article_year - 1;
    }
    var article_name = document.getElementsByName('article:slug')[0].content;
    var source_url = document.getElementsByName('source-repository')[0].content;
    if (source_url.endsWith('.git')) {
      source_url = source_url.slice(0, -4);
    } else if (url_base.endsWith('/')) {
      source_url = source_url.slice(0, -1);
    }
    var source_url_hierarchies = source_url.split('/');
    var repname = source_url_hierarchies.pop();
    var account = source_url_hierarchies.pop();
    var urlroot_colab = "https://colab.research.google.com/github/"+account+"/"+repname+"/blob/master/content/articles/";
    var urlroot_github = source_url + "/blob/master/content/articles/";
    var filepath = article_year+"sy/"+article_category+"/"+article_name+".ipynb"
    var colab_url = urlroot_colab + filepath;
    var github_url = urlroot_github + filepath;
    var site_url = document.getElementsByName('siteurl')[0].content;
    var button = '<a href='+github_url+'>'+github_img+'</a>'
               +'<a href='+colab_url+'>'+colab_img+'</a>';
    doc0.innerHTML= button;
}

$(function() {
  const myhost = $(location).attr('hostname'); /* hogehoge.github.io */
  /* in order to work only on github pages, add:
  if (! myhost.match(/^[^\.]+\.github\.io$/)) {
    return;
  }
  */
  const account = myhost.split('.')[0]; /* hogehoge */
  const repo = account + '/' + myhost + '/blob/master';
  const root = 'https://colab.research.google.com/github/' + repo;
  $('a').each(function() {
    const target = $(this).attr('href').replace('https://'+myhost, '');
    if ((target.startsWith('.') || target.startsWith('/')) && target.endsWith('.ipynb')) {
      let upper = root + $(location).attr('pathname');
      let upper_split = upper.split('/');
      let target_split = target.split('/');
      upper_split.pop();
      let head = true;
      while (true) {
        if (head && target_split[0] == '') {
          target_split.shift();
          upper_split = root.split('/');
          break;
        } else if (target_split[0] == '.') {
          target_split.shift();
          head = false;
        } else if (target_split[0] == '..') {
          target_split.shift();
          upper_split.pop();
          head = false;
        } else {
          break;
        }
      }
      colablink = upper_split.join('/') + '/' + target_split.join('/');
      $(this).after(' <a href='+colablink+'>'+colab_img+'</a>');
    }
  });
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script>
!function(t){"use strict";var n=function(n){return this.each(function(){var e,i,a=t(this),o=a.data(),c=[a],r=this.tagName,d=0;e=t.extend({content:"body",headings:"h1,h2,h3"},{content:o.toc||void 0,headings:o.tocHeadings||void 0},n),i=e.headings.split(","),t(e.content).find(e.headings).attr("id",function(n,e){return e||function(t){0===t.length&&(t="?");for(var n=t.replace(/\s+/g,"_"),e="",i=1;null!==document.getElementById(n+e);)e="_"+i++;return n+e}(t(this).text())}).each(function(){var n=t(this),e=t.map(i,function(t,e){return n.is(t)?e:void 0})[0];if(e>d){var a=c[0].children("li:last")[0];a&&c.unshift(t("<"+r+"/>").appendTo(a))}else c.splice(0,Math.min(d-e,Math.max(c.length-1,0)));var o=n.text();o=o.replace("¶",""),t("<li/>").appendTo(c[0]).append(t("<a/>").text(o).attr("href","#"+n.attr("id"))),d=e})})},e=t.fn.toc;t.fn.toc=n,t.fn.toc.noConflict=function(){return t.fn.toc=e,this},t(function(){n.call(t("[data-toc]"))})}(window.jQuery);
</script>
<script>
$(function(){
  $('a[href*="#"]').on('click',function() {
    var container = $('.container');
    var add_move = container.height() + 50
    var speed = 400;
    var href= $(this).attr("href");
    var target = $(href == "#" || href == "" ? 'html' : href);
    var position = target.offset().top - add_move;
    $('body,html').animate({scrollTop:position}, speed, 'swing');
    return false;
  });
});
</script>
<script type="text/javascript">
    $("#toc").toc({headings: "h2,h3"});
    if( $('#toc').is(':empty') ) {
      $('.toc_box').remove();
    }
</script><p class="pagetop" id="pagetop"><a href="#wrap"></a></p>
<script>
$(document).ready(function() {
    var pagetop = $('#pagetop');
    $(window).scroll(function () {
        if ($(this).scrollTop() > 600) {
            pagetop.fadeIn();
        } else {
            pagetop.fadeOut();
            }
        });
        pagetop.click(function () {
            $('body, html').animate({ scrollTop: 0 }, 500);
                return false;
    });
});
</script><script>
$('.dropdown-toggle').click(function() {
    var location = $(this).attr('href');
    window.location.href = location;
    return false;
});
</script>  </body>
</html>