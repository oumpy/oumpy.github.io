<!DOCTYPE html>
<html lang="ja">
<head>
          <title>大阪大学医学部Python会 - Hamiltonian Descent Methodの要点</title>
        <meta charset="utf-8" />




    <meta name="tags" content="deeplearning" />

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">大阪大学医学部Python会 <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="/category/atcoder.html">atcoder</a></li>
            <li><a href="/category/bioinformatics.html">bioinformatics</a></li>
            <li class="active"><a href="/category/deeplearning.html">deeplearning</a></li>
            <li><a href="/category/github.html">github</a></li>
            <li><a href="/category/kaggle.html">kaggle</a></li>
            <li><a href="/category/member.html">member</a></li>
            <li><a href="/category/paper.html">paper</a></li>
            <li><a href="/category/python.html">python</a></li>
            <li><a href="/category/shell.html">shell</a></li>
            <li><a href="/category/statistics.html">statistics</a></li>
            <li><a href="/category/tong-ji.html">統計</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="/hamiltonian_descent_method.html" rel="bookmark"
         title="Permalink to Hamiltonian Descent Methodの要点">Hamiltonian Descent Methodの要点</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2019-04-14T00:00:00+09:00">
      日 14 4月 2019
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="/author/shan-ben.html">山本</a>
    </address>
    <div class="category">
        Category: <a href="/category/deeplearning.html">deeplearning</a>
    </div>
    <div class="tags">
        Tags:
            <a href="/tag/deeplearning.html">deeplearning</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>解説自体は<a href="https://omedstu.jimdo.com/2018/09/26/hamiltonian-descent-methods%E3%81%AE%E5%AE%9F%E8%A3%85%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E8%A7%A3%E8%AA%AC/" target="_blank" rel="noopener">Hamiltonian Descent Methodsの実装についての解説</a>に書いたのですが、こちらには要点だけまとめておきます。</p>
<h3>要点のまとめ</h3>

<p><img class="aligncenter size-full wp-image-170" src="https://pythonoum.files.wordpress.com/2018/09/1537941381.jpg" alt="1537941381" width="800" height="269" />
- Hamiltonian Descent法を用いると凸関数最適化が高速かつ高精度で行える。
- 超収束(Super-Convergence, <a href="https://arxiv.org/pdf/1708.07120.pdf">arxiv</a>)とは関係ある？論文読んだ限りはなさそう。
- ニューラルネットワークの最適化に応用するには運動エネルギー関数の研究が必要。
- なぜ高速に学習できるのか、なぜSGDと比べてニューラルネットワークの学習が不能なのか不明。でも学習できるならもっと実装あるよなと思っています。</p>
<h3>アルゴリズム（1つ目の陽解法）</h3>

<p>パラメータx以外に運動量のパラメータpを用意します。以下の更新式に従ってパラメータを更新します。
<img class="aligncenter size-medium wp-image-168" src="https://pythonoum.files.wordpress.com/2018/09/texclip20180929003048.png?w=600" alt="texclip20180929003048" width="300" height="81" />
ここでx_tは時刻tにおける解、p_tは時刻tにおける運動量、kは運動エネルギー関数、fは最小化したい関数（位置エネルギー関数）です2回微分が必要ですが、運動エネルギー関数k(p)を解析的に微分可能にしておけば、∇k(p)を定義すれば微分は1回でokです。</p>
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>