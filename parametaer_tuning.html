<!DOCTYPE html>
<html lang="ja">
<head>
          <title>大阪大学医学部Python会 - Parameter Tuning</title>
        <meta charset="utf-8" />




    <meta name="tags" content="deeplearning" />

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">大阪大学医学部Python会 <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="/category/atcoder.html">atcoder</a></li>
            <li><a href="/category/bioinformatics.html">bioinformatics</a></li>
            <li class="active"><a href="/category/deeplearning.html">deeplearning</a></li>
            <li><a href="/category/github.html">github</a></li>
            <li><a href="/category/kaggle.html">kaggle</a></li>
            <li><a href="/category/member.html">member</a></li>
            <li><a href="/category/paper.html">paper</a></li>
            <li><a href="/category/python.html">python</a></li>
            <li><a href="/category/shell.html">shell</a></li>
            <li><a href="/category/statistics.html">statistics</a></li>
            <li><a href="/category/tong-ji.html">統計</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="/parametaer_tuning.html" rel="bookmark"
         title="Permalink to Parameter Tuning">Parameter Tuning</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2019-04-14T00:00:00+09:00">
      日 14 4月 2019
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="/author/zuo-teng.html">佐藤</a>
    </address>
    <div class="category">
        Category: <a href="/category/deeplearning.html">deeplearning</a>
    </div>
    <div class="tags">
        Tags:
            <a href="/tag/deeplearning.html">deeplearning</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>機械学習を行う際に大事なのがパラメーターの調整です。
今まで適当にデフォルトの値でそのままやったりGridearchで探したりしていましたが、結構時間かかるので他の有効な方法を探して、手元で実際に動かして見ました。<a href="http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html">こちら</a>の資料がわかりやすかったです。(図もこちらのものを引用しました)</p>
<h2>Bayesian Optimization</h2>

<p><strong>Bayesian Optimization</strong>はパラメーターを<strong>x</strong>、評価値(精度とか)をyとして</p>
<p><img src="https://github.com/jun-sato/parameter_tuning/blob/master/suushiki0.png?raw=true" alt="suushiki0" /></p>
<p>という関数を指定します(ブラックボックス関数)。中身は良くわかりませんが、この関数を最適化するパラメーターを見つけたいと思います。そこでBaysian Optimizationはこの関数が<a href="http://www.yasuhisay.info/entry/20091011/1255189429">ガウス過程</a>に従うと仮定します。</p>
<p>下の図ではパラメーターの組み合わせをそれぞれ2,3個とって来て、その評価値を計算して結果をプロットしたグラフです。青い曲線はこの二点から導かれる関数の事後分布で、青い部分はこの分布の95%信頼区間です。</p>
<p><img src="http://neupy.com/_images/gaussian-process-example.png" alt="Baysian Optimization" /></p>
<p>このグラフを見ると、観測点から離れた部分は信頼区間の幅が広い(=σが大きい)ことがわかります。</p>
<h3>獲得関数(Acquisition Function)</h3>

<p>獲得関数は、次にどこの点を観測するか決める関数です。これにはいろいろな関数がありますが、よく使われるのが</p>
<p><img src="https://github.com/jun-sato/parameter_tuning/blob/master/suushiki2.png?raw=True" alt="suushiki2" /></p>
<p>という<strong>Expected Improvement</strong>[Mockus,1978]であったり、
<img src="https://github.com/jun-sato/parameter_tuning/blob/master/suushiki1.png?raw=True" alt="suushiki1" /></p>
<p>のような<strong>Mutual Information</strong>[Contal+2014]がよく使われます。後者は特に直感的にわかりやすいと思うのですが、私たちも次にどの点を選ぶかというときに</p>
<ul>
<li>観測した点から推測して精度が良さそうな点を選びたい(μが大きい)</li>
<li>まだ観測していない場所から選びたい(σが大きい)</li>
</ul>

<p>ということを考えて選びそうなものです。よくできてますね。</p>
<p><img src="http://neupy.com/_images/expected-improvement-example.png" alt="acquisition function" /></p>
<p>実装には<a href="https://github.com/fmfn/BayesianOptimization">Bayesian Optimization</a>を使いました。</p>
<p>使用するデータはkaggleの<a href="https://www.kaggle.com/c/otto-group-product-classification-challenge#evaluation">Otto Group Product Classification Challenge</a>のデータで評価指標はmulti-class loglossです。定番のXGBoostのパラメータを最適化します。</p>
<p><code>pip install bayesian-optimization</code></p>
<p>[code lang="text"]
import pandas as pd
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
from bayes_opt import BayesianOptimization
[/code]</p>
<p>調整したいパラメーターを引数にとる評価関数の指定、クロスバリデーション。bayesian-optimizationには評価関数の最大化のライブラリしかないので、小さい値ほどいいloglossは返り値に-1をかけます。</p>
<p>[code lang="text"]
def xgb_evaluate(min_child_weight,
colsample_bytree,
max_depth,
subsample,
gamma,
alpha):</p>
<p>params[&#039;min_child_weight&#039;] = int(min_child_weight)
params[&#039;cosample_bytree&#039;] = max(min(colsample_bytree, 1), 0)
params[&#039;max_depth&#039;] = int(max_depth)
params[&#039;subsample&#039;] = max(min(subsample, 1), 0)
params[&#039;gamma&#039;] = max(gamma, 0)
params[&#039;alpha&#039;] = max(alpha, 0)</p>
<p>cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,
seed=random_state,
callbacks=[xgb.callback.early_stop(50)])</p>
<p>return -cv_result[&#039;test-mlogloss-mean&#039;].values[-1]
[/code]</p>
<p>いよいよ最適化！</p>
<p>[code lang="text"]
if <strong>name</strong> == &#039;<strong>main</strong>&#039;:
xgtrain = prepare_data()</p>
<p>num_rounds = 3000
random_state = 2016
num_iter = 25
init_points = 5
params = {
&#039;eta&#039;: 0.1,
&#039;silent&#039;: 1,
&#039;eval_metric&#039;: &#039;mlogloss&#039;,
&#039;verbose_eval&#039;: True,
&#039;seed&#039;: random_state,
&#039;num_class&#039;:9
}</p>
<p>xgbBO = BayesianOptimization(xgb_evaluate, {&#039;min_child_weight&#039;: (1, 20),
&#039;colsample_bytree&#039;: (0.1, 1),
&#039;max_depth&#039;: (5, 15),
&#039;subsample&#039;: (0.5, 1),
&#039;gamma&#039;: (0, 10),
&#039;alpha&#039;: (0, 10),
})</p>
<p>xgbBO.maximize(init_points=init_points, n_iter=num_iter)
[/code]</p>
<p>結果です</p>
<p><img src="https://github.com/jun-sato/parameter_tuning/blob/master/result.png?raw=true" alt="result" />
<img src="https://github.com/jun-sato/parameter_tuning/blob/master/result2.png?raw=true" alt="result2" /></p>
<p>だいたい15回くらいの試行でloglossが0.46136まで下がりました。やってから気づいたんですが、max_depthとかって整数の値しかとらないですね、、、</p>
<p>ただし、ベイズ最適化には弱点もいくつかあって、</p>
<ul>
<li>カテゴリー変数の場合にうまくいかない。</li>
<li>偶然性に左右されたり、再現性が取れないことがある</li>
<li>バラメーターが増えてきたら時間かかる</li>
</ul>

<p>みたいなことになるらしいです。</p>
<h2>Tree-structured Parzen Estimator(TPE)</h2>

<p>このような弱点を修正したのがTPEという最適化手法です。ベイズとコンセプトは似ていますが、手法は全く異なります。一般的な方法として、まずRandom Searchを用いていくつか点をとってきます。プロットすると下の図のようになりました。</p>
<p><img src="http://neupy.com/_images/tpe-observation-groups.png" alt="TPE" /></p>
<p>次に精度が良かったもの(図では上位20%)とそうでなかったものに分けます。この2群の尤度関数を求めます。あまり尤度と言っても馴染みのない人が多いと思いますが、サンプリングされたデータは様々な確率分布のうち、どの分布から得られたものとするのが一番尤もらしいかを決めようとするものです。これにより2群の確率分布が出来上がります。</p>
<p>TPEでもExpected Improvement関数の下のように定義します。精度良かったものをl,そうではなかったものをgとして、</p>
<p><img src="https://github.com/jun-sato/parameter_tuning/blob/master/suushiki3.png?raw=True" alt="suushiki3" />
これをそれぞれの観測点に対して適用し、最もEIの値が大きかった場所が次の観測点になります。</p>
<p><img src="http://neupy.com/_images/tpe-sampled-candidates.png" alt="prob dist" />
<img src="http://neupy.com/_images/tpe-expected-improvement.png" alt="acq" /></p>
<p>こっちも実装してみます。Pythonではhyperoptというライブラリがあってpipで入ります。</p>
<p><code>pip install hyperopt</code></p>
<p>[code lang="text"]
import hyperopt
from hyperopt import hp, tpe, Trials, fmin
[/code]</p>
<p>最適化するパラメータはbayesian optimizationと同じやつにしてみました。</p>
<p>[code lang="text"]
hyperopt_parameters = {&#039;min_child_weight&#039;: hp.uniform(&#039;min_child_weight&#039;,1,20),
&#039;colsample_bytree&#039;: hp.uniform(&#039;colsample_bytree&#039;,0.1, 1),
&#039;max_depth&#039;: hp.choice(&#039;max_depth&#039;,np.arange(5, 15)),
&#039;subsample&#039;: hp.uniform(&#039;subsample&#039;,0.5, 1),
&#039;gamma&#039;: hp.uniform(&#039;gamma&#039;,0, 10),
&#039;alpha&#039;: hp.uniform(&#039;alpha&#039;,0, 10),
}
[/code]</p>
<p>最適化する関数の指定</p>
<p>[code lang="text"]
def objective(args):
classifier = xgb.XGBClassifier(**args)
stratifiedkfold = StratifiedKFold(n_splits=5)
result = cross_val_score(classifier, train.drop([&#039;id&#039;,&#039;target&#039;],axis = 1), train.target, cv=stratifiedkfold,scoring=&#039;neg_log_loss&#039;)
return -result.mean()
[/code]</p>
<p>実行！</p>
<p>[code lang="text"]
max_evals = 50
trials = Trials() # 実行結果を格納するインスタンス</p>
<p>best = fmin(
objective,
hyperopt_parameters,
algo = tpe.suggest,
max_evals =max_evals,
trials = trials,
verbose = 1)
[/code]</p>
<h3>結果</h3>

<p><img src="https://github.com/jun-sato/parameter_tuning/blob/master/loss.jpg?raw=true" alt="loss" /></p>
<p><img src="https://github.com/jun-sato/parameter_tuning/blob/master/best_param.png?raw=true" alt="best_param" /></p>
<p>logloss最小値は0.4749でした。あれ、bayesian optimizaationより悪い、、、bayesianではmax_depthを整数に限定しなかったからかも、、
でも自分で手動でやった時は0.6とかだったんで、パラメーターチューニングの時にはこれからこれ使っていこうと思います。あとこのxgboost動かすのに8コアCPU使ってそれぞれ半日くらい回しました。GPU使ってたらもうちょい早かったと思うのですが、きちんとbuildとmakeしてもうまくいきませんでした。また挑戦します。</p>
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>